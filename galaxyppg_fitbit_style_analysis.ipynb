{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GalaxyPPG (P01) — Fitbit-style Analysis Notebook\n",
        "\n",
        "This notebook mirrors the structure you saw in Fitbit repos:\n",
        "\n",
        "1. Setup & Data Collection\n",
        "2. Data Loading\n",
        "3. Activity & Fitness (PPG-equivalent)\n",
        "4. Heart Monitoring (PPG vs ECG ground truth)\n",
        "5. Heart Rate Variability (HRV)\n",
        "6. Reliability-first insight (SQI + abstain)\n",
        "7. Export artifacts (GitHub-safe)\n",
        "\n",
        "**Dataset mapping (your folder structure):**\n",
        "- **Polar H10 (ECG reference):** `Dataset/P01/PolarH10/` → ground-truth HR/HRV\n",
        "- **Empatica E4 (wrist PPG):** `Dataset/P01/E4/` → wearable PPG (BVP) + motion (ACC)\n",
        "\n",
        "**Novel angle:** compute **SQI** (signal quality) and only trust HR/HRV when SQI is good (deployment-like behavior)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------\n",
        "# 0) Config\n",
        "# ----------------\n",
        "DATASET_DIR = \"Dataset\"   # points to the folder containing Meta.csv and P01..P24\n",
        "SUBJECT = \"P01\"\n",
        "\n",
        "# Windowing (real-time style)\n",
        "FS_TARGET = None          # if None, infer from file when possible\n",
        "WIN_SEC = 10.0\n",
        "STEP_SEC = 2.0\n",
        "\n",
        "# SQI threshold (quantile): lower -> stricter, higher -> more permissive\n",
        "SQI_NOISY_QUANTILE = 0.35\n",
        "\n",
        "ARTIFACTS_DIR = \"artifacts\"\n",
        "\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.signal import butter, filtfilt, welch\n",
        "\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
        "np.random.seed(42)\n",
        "plt.rcParams[\"figure.figsize\"] = (11, 4)\n",
        "\n",
        "print(\"Dataset dir:\", os.path.abspath(DATASET_DIR))\n",
        "print(\"Subject:\", SUBJECT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup & Data Collection\n",
        "\n",
        "We load metadata (`Meta.csv`) and identify participant context (age, gender, stress scores, watch side)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_path = os.path.join(DATASET_DIR, \"Meta.csv\")\n",
        "meta = pd.read_csv(meta_path)\n",
        "meta_row = meta[meta[\"UID\"] == SUBJECT].iloc[0]\n",
        "display(meta_row)\n",
        "\n",
        "print(\"Age:\", meta_row.get(\"AGE\"), \" Gender:\", meta_row.get(\"GENDER\"))\n",
        "print(\"TSST:\", meta_row.get(\"TSST\"), \" SSST:\", meta_row.get(\"SSST\"), \" Watch side:\", meta_row.get(\"GalaxyWatch\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Data Loading\n",
        "\n",
        "We load:\n",
        "- **E4/BVP.csv** (wrist PPG)\n",
        "- **E4/ACC.csv** (motion)\n",
        "- **PolarH10/IBI.csv** (ECG-derived inter-beat intervals; best for HRV)\n",
        "\n",
        "The loader below supports:\n",
        "- Empatica-style CSV (start timestamp row + sample rate row + values)\n",
        "- Standard CSV with time/value columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _try_read_csv(path):\n",
        "    # robust CSV reading\n",
        "    return pd.read_csv(path, header=None)\n",
        "\n",
        "def load_empatica_signal(path, n_axes=1):\n",
        "    \"\"\"\n",
        "    Empatica-format often:\n",
        "      row0: start_time_epoch_seconds\n",
        "      row1: sampling_rate_hz\n",
        "      rows2..: samples (1 col for BVP/TEMP; 3 cols for ACC)\n",
        "\n",
        "    Also supports normal CSV with headers like time/value.\n",
        "    Returns: t (seconds from start), x (np array), fs (float or None)\n",
        "    \"\"\"\n",
        "    # First, attempt normal header read\n",
        "    try:\n",
        "        dfh = pd.read_csv(path)\n",
        "        cols = [c.lower() for c in dfh.columns]\n",
        "        # if it looks like a normal table with time & value\n",
        "        time_col = None\n",
        "        for c in dfh.columns:\n",
        "            if str(c).lower() in [\"time\", \"timestamp\", \"t\", \"datetime\", \"date\"]:\n",
        "                time_col = c\n",
        "                break\n",
        "        if time_col is not None and len(dfh.columns) >= 2:\n",
        "            # pick remaining numeric cols as signal\n",
        "            sig_cols = [c for c in dfh.columns if c != time_col]\n",
        "            x = dfh[sig_cols].to_numpy(dtype=np.float32)\n",
        "            t_raw = dfh[time_col].to_numpy()\n",
        "            # Try to convert time to seconds-from-start\n",
        "            try:\n",
        "                t_raw = t_raw.astype(np.float64)\n",
        "                t = t_raw - t_raw[0]\n",
        "            except Exception:\n",
        "                t = np.arange(len(x), dtype=np.float32)\n",
        "            fs = None\n",
        "            return t.astype(np.float32), x, fs\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Fall back to Empatica-format (no header)\n",
        "    df = _try_read_csv(path)\n",
        "    # Expect at least 3 rows\n",
        "    if df.shape[0] < 3:\n",
        "        raise ValueError(f\"Unexpected format: {path}\")\n",
        "\n",
        "    start = float(df.iloc[0, 0])\n",
        "    fs = float(df.iloc[1, 0])\n",
        "    values = df.iloc[2:, :n_axes].to_numpy(dtype=np.float32)\n",
        "    n = values.shape[0]\n",
        "    t = (np.arange(n, dtype=np.float32) / fs)\n",
        "    return t, values, fs\n",
        "\n",
        "def load_ibi(path):\n",
        "    \"\"\"Load IBI file. Tries common formats.\n",
        "    Returns: t (seconds from start), ibi_sec (float)\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    cols = [c.lower() for c in df.columns]\n",
        "    # common: columns like 'timestamp' and 'ibi' or 'ibi_s'\n",
        "    time_col = None\n",
        "    for cand in [\"time\", \"timestamp\", \"t\", \"date\"]:\n",
        "        if cand in cols:\n",
        "            time_col = df.columns[cols.index(cand)]\n",
        "            break\n",
        "    # if no explicit time column, use first column as time\n",
        "    if time_col is None:\n",
        "        time_col = df.columns[0]\n",
        "\n",
        "    # ibi column: look for 'ibi'\n",
        "    ibi_col = None\n",
        "    for cand in [\"ibi\", \"ibi_s\", \"ibi_sec\", \"rr\", \"rr_interval\", \"rrinterval\"]:\n",
        "        if cand in cols:\n",
        "            ibi_col = df.columns[cols.index(cand)]\n",
        "            break\n",
        "    if ibi_col is None:\n",
        "        # if only 2 cols, assume second is ibi\n",
        "        if len(df.columns) >= 2:\n",
        "            ibi_col = df.columns[1]\n",
        "        else:\n",
        "            raise ValueError(f\"Cannot find IBI column in {path}. Columns={df.columns.tolist()}\")\n",
        "\n",
        "    t_raw = df[time_col].to_numpy()\n",
        "    ibi = df[ibi_col].to_numpy(dtype=np.float32)\n",
        "\n",
        "    # Convert time to seconds-from-start if numeric, else index-based\n",
        "    try:\n",
        "        t_raw = t_raw.astype(np.float64)\n",
        "        t = (t_raw - t_raw[0]).astype(np.float32)\n",
        "    except Exception:\n",
        "        t = np.arange(len(ibi), dtype=np.float32)\n",
        "\n",
        "    # Convert ibi to seconds if it looks like milliseconds\n",
        "    if np.nanmedian(ibi) > 5.0:  # likely ms\n",
        "        ibi = ibi / 1000.0\n",
        "    return t, ibi\n",
        "\n",
        "subj_dir = os.path.join(DATASET_DIR, SUBJECT)\n",
        "e4_dir = os.path.join(subj_dir, \"E4\")\n",
        "polar_dir = os.path.join(subj_dir, \"PolarH10\")\n",
        "\n",
        "bvp_path = os.path.join(e4_dir, \"BVP.csv\")\n",
        "acc_path = os.path.join(e4_dir, \"ACC.csv\")\n",
        "ibi_path = os.path.join(polar_dir, \"IBI.csv\")\n",
        "\n",
        "assert os.path.exists(bvp_path), f\"Missing: {bvp_path}\"\n",
        "assert os.path.exists(acc_path), f\"Missing: {acc_path}\"\n",
        "assert os.path.exists(ibi_path), f\"Missing: {ibi_path}\"\n",
        "\n",
        "t_bvp, bvp, fs_bvp = load_empatica_signal(bvp_path, n_axes=1)\n",
        "t_acc, acc, fs_acc = load_empatica_signal(acc_path, n_axes=3)\n",
        "t_ibi, ibi = load_ibi(ibi_path)\n",
        "\n",
        "bvp = bvp.squeeze(-1) if bvp.ndim == 2 and bvp.shape[1] == 1 else bvp\n",
        "\n",
        "print(\"BVP:\", bvp.shape, \" fs:\", fs_bvp)\n",
        "print(\"ACC:\", acc.shape, \" fs:\", fs_acc)\n",
        "print(\"IBI:\", ibi.shape, \" (seconds)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick visual check (raw)\n",
        "We plot a short segment of wrist PPG (BVP), motion magnitude, and IBI sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def acc_magnitude(a):\n",
        "    a = np.asarray(a, dtype=np.float32)\n",
        "    if a.ndim == 2 and a.shape[1] >= 3:\n",
        "        return np.sqrt((a[:,0]**2) + (a[:,1]**2) + (a[:,2]**2))\n",
        "    return np.abs(a).astype(np.float32)\n",
        "\n",
        "acc_mag = acc_magnitude(acc)\n",
        "\n",
        "n_bvp = min(len(bvp), int((fs_bvp or 64) * 20))\n",
        "plt.figure(); plt.plot(t_bvp[:n_bvp], bvp[:n_bvp]); plt.title(\"E4 BVP (raw) — first ~20s\"); plt.xlabel(\"sec\"); plt.show()\n",
        "\n",
        "n_acc = min(len(acc_mag), int((fs_acc or 32) * 20))\n",
        "plt.figure(); plt.plot(t_acc[:n_acc], acc_mag[:n_acc]); plt.title(\"E4 ACC magnitude — first ~20s\"); plt.xlabel(\"sec\"); plt.show()\n",
        "\n",
        "plt.figure(); plt.plot(t_ibi[:min(len(ibi),200)], ibi[:min(len(ibi),200)]); plt.title(\"Polar IBI (sec) — first 200 intervals\"); plt.xlabel(\"sec\"); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Activity & Fitness (PPG-equivalent)\n",
        "\n",
        "Fitbit has steps/active minutes. Here we use wearable equivalents:\n",
        "- **Motion** (ACC magnitude)\n",
        "- **Signal quality (SQI)**: how concentrated the spectrum is in plausible HR band\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bandpass_ppg(x, fs, low=0.7, high=4.0):\n",
        "    b, a = butter(3, [low/(fs/2), high/(fs/2)], btype='band')\n",
        "    return filtfilt(b, a, x).astype(np.float32)\n",
        "\n",
        "def zscore(x, eps=1e-8):\n",
        "    x = x.astype(np.float32)\n",
        "    return (x - x.mean()) / (x.std() + eps)\n",
        "\n",
        "def window_signal(x, fs, win_sec, step_sec):\n",
        "    win = int(win_sec*fs)\n",
        "    step = int(step_sec*fs)\n",
        "    out, centers = [], []\n",
        "    for s in range(0, len(x)-win+1, step):\n",
        "        out.append(x[s:s+win])\n",
        "        centers.append((s + win/2)/fs)\n",
        "    return (np.stack(out) if out else np.zeros((0, win), dtype=np.float32)), np.array(centers, dtype=np.float32)\n",
        "\n",
        "def sqi_power_ratio(ppg, fs):\n",
        "    f, pxx = welch(ppg, fs=fs, nperseg=min(len(ppg), int(fs*4)))\n",
        "    total = np.trapz(pxx, f) + 1e-12\n",
        "    band = (f >= 0.7) & (f <= 4.0)\n",
        "    bandp = np.trapz(pxx[band], f[band])\n",
        "    return float(bandp/total)\n",
        "\n",
        "def hr_from_psd(ppg, fs):\n",
        "    f, pxx = welch(ppg, fs=fs, nperseg=min(len(ppg), int(fs*4)))\n",
        "    band = (f >= 0.7) & (f <= 4.0)\n",
        "    fb, pb = f[band], pxx[band]\n",
        "    if len(fb) == 0:\n",
        "        return float(\"nan\")\n",
        "    return float(fb[int(np.argmax(pb))] * 60.0)\n",
        "\n",
        "# Infer FS\n",
        "FS_PPG = int(round(fs_bvp)) if fs_bvp is not None else 64\n",
        "FS_ACC = int(round(fs_acc)) if fs_acc is not None else 32\n",
        "print(\"Using FS_PPG=\", FS_PPG, \"FS_ACC=\", FS_ACC)\n",
        "\n",
        "bvp_f = zscore(bandpass_ppg(bvp, FS_PPG))\n",
        "\n",
        "X_ppg, t_center = window_signal(bvp_f, FS_PPG, WIN_SEC, STEP_SEC)\n",
        "X_acc, _ = window_signal(acc_mag, FS_ACC, WIN_SEC, STEP_SEC)\n",
        "\n",
        "sqi = np.array([sqi_power_ratio(w, FS_PPG) for w in X_ppg], dtype=np.float32)\n",
        "motion = np.array([float(np.mean(w)) for w in X_acc], dtype=np.float32)\n",
        "\n",
        "thr = float(np.quantile(sqi, SQI_NOISY_QUANTILE))\n",
        "clean = (sqi >= thr).astype(int)\n",
        "\n",
        "print(\"windows:\", len(sqi), \" SQI_thr:\", thr, \" clean%:\", clean.mean()*100)\n",
        "\n",
        "plt.figure(); plt.hist(sqi, bins=50); plt.axvline(thr); plt.title(\"SQI distribution\"); plt.show()\n",
        "plt.figure(); plt.scatter(motion, sqi, s=8); plt.title(\"Motion vs SQI\"); plt.xlabel(\"ACC magnitude (mean)\"); plt.ylabel(\"SQI\"); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Heart Monitoring (PPG vs ECG ground truth)\n",
        "\n",
        "Ground truth is computed from **Polar IBI**:\n",
        "- HR_true(window) = 60 / mean(IBI in window)\n",
        "\n",
        "Wearable estimate from wrist PPG (BVP):\n",
        "- HR_pred(window) from PSD peak\n",
        "\n",
        "**Reliability-first:** Compare error vs SQI and show improvement when we abstain on noisy windows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hr_from_ibi_window(t_ibi, ibi, t0, t1):\n",
        "    mask = (t_ibi >= t0) & (t_ibi < t1)\n",
        "    if not np.any(mask):\n",
        "        return float(\"nan\")\n",
        "    m = float(np.nanmean(ibi[mask]))\n",
        "    if m <= 0:\n",
        "        return float(\"nan\")\n",
        "    return 60.0 / m\n",
        "\n",
        "hr_true = []\n",
        "hr_pred = []\n",
        "\n",
        "for tc, w in zip(t_center, X_ppg):\n",
        "    t0 = float(tc - WIN_SEC/2)\n",
        "    t1 = float(tc + WIN_SEC/2)\n",
        "    hr_true.append(hr_from_ibi_window(t_ibi, ibi, t0, t1))\n",
        "    hr_pred.append(hr_from_psd(w, FS_PPG))\n",
        "\n",
        "hr_true = np.array(hr_true, dtype=np.float32)\n",
        "hr_pred = np.array(hr_pred, dtype=np.float32)\n",
        "\n",
        "valid = np.isfinite(hr_true) & np.isfinite(hr_pred)\n",
        "mae_all = np.mean(np.abs(hr_true[valid] - hr_pred[valid]))\n",
        "\n",
        "valid_clean = valid & (clean == 1)\n",
        "mae_clean = np.mean(np.abs(hr_true[valid_clean] - hr_pred[valid_clean])) if np.any(valid_clean) else float(\"nan\")\n",
        "coverage = float(np.mean(valid_clean)) * 100\n",
        "\n",
        "print(f\"HR MAE (all valid windows):   {mae_all:.2f} bpm\")\n",
        "print(f\"HR MAE (clean only):          {mae_clean:.2f} bpm | coverage={coverage:.1f}%\")\n",
        "\n",
        "plt.figure();\n",
        "plt.plot(hr_pred[:300], label='HR_pred (PPG)')\n",
        "plt.plot(hr_true[:300], label='HR_true (Polar IBI)')\n",
        "plt.title('Heart rate — first 300 windows')\n",
        "plt.legend();\n",
        "plt.show()\n",
        "\n",
        "err = np.abs(hr_true - hr_pred)\n",
        "plt.figure();\n",
        "plt.scatter(sqi[valid], err[valid], s=8)\n",
        "plt.title('HR absolute error vs SQI')\n",
        "plt.xlabel('SQI')\n",
        "plt.ylabel('|HR_true - HR_pred|')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Heart Rate Variability (HRV)\n",
        "\n",
        "Compute time-domain HRV from **Polar IBI** per window:\n",
        "- **RMSSD**\n",
        "- **SDNN**\n",
        "\n",
        "**Novel reliability behavior:** HRV is only interpreted on clean windows (SQI high)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hrv_rmssd_sdnn(ibi_sec):\n",
        "    ibi_sec = np.asarray(ibi_sec, dtype=np.float32)\n",
        "    ibi_sec = ibi_sec[np.isfinite(ibi_sec)]\n",
        "    if len(ibi_sec) < 4:\n",
        "        return float('nan'), float('nan')\n",
        "    diff = np.diff(ibi_sec)\n",
        "    rmssd = float(np.sqrt(np.mean(diff**2)))\n",
        "    sdnn = float(np.std(ibi_sec))\n",
        "    return rmssd, sdnn\n",
        "\n",
        "rmssd_list, sdnn_list = [], []\n",
        "for tc in t_center:\n",
        "    t0 = float(tc - WIN_SEC/2)\n",
        "    t1 = float(tc + WIN_SEC/2)\n",
        "    mask = (t_ibi >= t0) & (t_ibi < t1)\n",
        "    r, s = hrv_rmssd_sdnn(ibi[mask])\n",
        "    rmssd_list.append(r)\n",
        "    sdnn_list.append(s)\n",
        "\n",
        "rmssd = np.array(rmssd_list, dtype=np.float32)\n",
        "sdnn = np.array(sdnn_list, dtype=np.float32)\n",
        "\n",
        "plt.figure(); plt.hist(rmssd[np.isfinite(rmssd)], bins=40); plt.title(\"RMSSD (Polar) per window\"); plt.show()\n",
        "plt.figure(); plt.hist(sdnn[np.isfinite(sdnn)], bins=40); plt.title(\"SDNN (Polar) per window\"); plt.show()\n",
        "\n",
        "# show clean-only distributions\n",
        "plt.figure(); plt.hist(rmssd[(clean==1) & np.isfinite(rmssd)], bins=40); plt.title(\"RMSSD (Polar) — clean windows only\"); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Reliability-first summary (P01)\n",
        "\n",
        "We export a compact, GitHub-safe table:\n",
        "- window center time\n",
        "- SQI\n",
        "- motion\n",
        "- HR_true (Polar)\n",
        "- HR_pred (PPG)\n",
        "- RMSSD/SDNN (Polar)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out = pd.DataFrame({\n",
        "    \"UID\": SUBJECT,\n",
        "    \"t_center_sec\": t_center,\n",
        "    \"sqi\": sqi,\n",
        "    \"clean\": clean,\n",
        "    \"motion_mean\": motion,\n",
        "    \"hr_true_polar\": hr_true,\n",
        "    \"hr_pred_ppg\": hr_pred,\n",
        "    \"hr_abs_err\": np.abs(hr_true - hr_pred),\n",
        "    \"rmssd_polar\": rmssd,\n",
        "    \"sdnn_polar\": sdnn,\n",
        "    \"TSST\": meta_row.get(\"TSST\"),\n",
        "    \"SSST\": meta_row.get(\"SSST\"),\n",
        "    \"WatchSide\": meta_row.get(\"GalaxyWatch\"),\n",
        "})\n",
        "\n",
        "save_path = os.path.join(ARTIFACTS_DIR, f\"{SUBJECT}_window_metrics.csv\")\n",
        "out.to_csv(save_path, index=False)\n",
        "print(\"Saved:\", save_path)\n",
        "out.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Next step: scale to all subjects\n",
        "\n",
        "Once P01 looks correct (plots, FS, file parsing), we will:\n",
        "\n",
        "- wrap the P01 pipeline into `process_subject(uid)`\n",
        "- loop over `Meta.csv[UID]` (P01–P24)\n",
        "- concatenate outputs into one dataset\n",
        "- add per-subject summary tables (MAE all vs clean, coverage)\n",
        "\n",
        "✅ This is exactly how Fitbit repos scale from one user to many."
      ]
    }
  ],
  "metadata": {
    "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
    "language_info": { "name": "python", "version": "3.10" }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

